{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import load_iris\n",
    "iris_X, iris_y = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementasi pembentukan confusion matrix saat prediksi batch, dan implementasi juga perhitungan akurasi, precision, recall, dan F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\"model.txt\")\n",
    "    \n",
    "mini_batch_X = []\n",
    "mini_batch_y = []\n",
    "batches_X = []\n",
    "batches_y = []\n",
    "\n",
    "for i in range (len(iris_X)):\n",
    "    mini_batch_X.append(iris_X[i])\n",
    "    mini_batch_y.append(iris_y[i])\n",
    "    if (i % model.batch_size == model.batch_size - 1): # isi mini_batch sebanyak batch_size\n",
    "        batches_X.append(mini_batch_X)\n",
    "        batches_y.append(mini_batch_y)\n",
    "        mini_batch_X = []\n",
    "        mini_batch_y = []\n",
    "outputs = model.fit(batches_X, batches_y, 0.1, 1, 20)\n",
    "pred = np.concatenate(outputs, axis=0) \n",
    "pred = np.round(pred)\n",
    "pred = pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi fungsi\n",
    "def confusion_matrix_scratch(true, pred):\n",
    "\n",
    "  N = len(set(true))\n",
    "  indexnum = [i for i in range(N)]\n",
    "  key =[\"{}{}\".format(x,y) for x in indexnum for y in indexnum]\n",
    "  temp = dict((el,0) for el in key)  \n",
    "  for i in range(len(true)):\n",
    "    key = \"{}{}\".format(true[i],pred[i])\n",
    "    if key in temp:\n",
    "      temp[key] +=1\n",
    "    else :\n",
    "      temp[key] = 1\n",
    "  reslist = list(temp.values())\n",
    "  return np.array([reslist[x:x+N] for x in range(0, len(reslist), N)])\n",
    "\n",
    "\n",
    "def accuracy(true,pred):\n",
    "  count =0\n",
    "  for i in range (len(true)):\n",
    "    count += 1 if(true[i]==pred[i]) else 0 \n",
    "  return count/len(true)\n",
    "\n",
    "def zero_division(n, d, div):\n",
    "    if (d == 0):\n",
    "        return div\n",
    "    else:\n",
    "        return n / d\n",
    "\n",
    "def recall(confMatrix, zero_div):\n",
    "    rec_arr = []\n",
    "    for i in range(len(confMatrix)):\n",
    "        sum = 0\n",
    "        for j in range(len(confMatrix)):\n",
    "            sum = sum + confMatrix[i][j]\n",
    "        rec_arr.append(zero_division(confMatrix[i][i], sum, zero_div))\n",
    "        \n",
    "    return rec_arr\n",
    "\n",
    "\n",
    "def weighted_recall(confMatrix, samples, zero_div):\n",
    "    rec_arr = recall(confMatrix, zero_div)\n",
    "    \n",
    "    w_rec = 0\n",
    "    sum = 0\n",
    "    for i in range(len(rec_arr)):\n",
    "        w_rec = w_rec + rec_arr[i] * samples[i]\n",
    "        sum = sum + samples[i]\n",
    "    \n",
    "    return zero_division(w_rec, sum, zero_div)\n",
    "\n",
    "def precision(confMatrix, zero_div):\n",
    "    prec_arr = []\n",
    "    for i in range(len(confMatrix)):\n",
    "        sum = 0\n",
    "        for j in range(len(confMatrix)):\n",
    "            sum = sum + confMatrix[j][i]\n",
    "        prec_arr.append(zero_division(confMatrix[i][i], sum, zero_div))\n",
    "        \n",
    "    return prec_arr\n",
    "\n",
    "def weighted_precision(confMatrix, samples, zero_div):\n",
    "    prec_arr = precision(confMatrix, zero_div)\n",
    "    w_prec = 0\n",
    "    sum = 0\n",
    "    for i in range(len(prec_arr)):\n",
    "        w_prec = w_prec + prec_arr[i] * samples[i]\n",
    "        sum = sum + samples[i]\n",
    "    \n",
    "    return zero_division(w_prec, sum, zero_div)\n",
    "\n",
    "\n",
    "def f1_scratch(prec, rec,zero_div):\n",
    "    f1_arr = []\n",
    "    for i in range(len(prec)):\n",
    "        f1 = zero_division(2 * prec[i] * rec[i], (prec[i] + rec[i]),zero_div)\n",
    "        f1_arr.append(f1)\n",
    "        \n",
    "    return f1_arr\n",
    "\n",
    "def weighted_f1(confMatrix, samples, zero_div):\n",
    "    prec_arr = precision(confMatrix,zero_div)\n",
    "    rec_arr = recall(confMatrix,zero_div)\n",
    "    f1_arr = f1_scratch(prec_arr, rec_arr,zero_div)\n",
    "\n",
    "    w_f1 = 0\n",
    "    sum = 0\n",
    "    for i in range(len(f1_arr)):\n",
    "        w_f1 = w_f1 + f1_arr[i] * samples[i]\n",
    "        sum = sum + samples[i]\n",
    "    \n",
    "    return zero_division(w_f1, sum, zero_div)\n",
    "\n",
    "def weight_f1score(arr):\n",
    "    N = len(set(arr))\n",
    "    temp = [0]*N\n",
    "    for i in range(len(arr)):\n",
    "        temp[arr[i]] +=1\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lakukan pengujian dengan membandingkan confusion matrix dan perhitungan kinerja dari sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pengujian menggunakan fungsi implementasi:\n",
      "confusion_matrix\n",
      "[[35 10  5]\n",
      " [10 40  0]\n",
      " [ 0 10 40]]\n",
      "accuracy =  0.7666666666666667\n",
      "precision =  0.7777777777777778\n",
      "recall =  0.7666666666666667\n",
      "f1 score =  0.7687400318979266\n"
     ]
    }
   ],
   "source": [
    "# Implementasi \n",
    "print(\"Pengujian menggunakan fungsi implementasi:\")\n",
    "print(\"confusion_matrix\")\n",
    "conf = confusion_matrix_scratch(iris_y,pred)\n",
    "print(conf)\n",
    "print(\"accuracy = \",accuracy(iris_y,pred))\n",
    "weight = weight_f1score(iris_y)\n",
    "print(\"precision = \", weighted_precision(conf,weight ,0))\n",
    "print(\"recall = \", weighted_recall(conf,weight,0))\n",
    "print(\"f1 score = \",weighted_f1(conf,weight,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pengujian menggunakan sklearn:\n",
      "confusion_matrix\n",
      "[[35 10  5]\n",
      " [10 40  0]\n",
      " [ 0 10 40]]\n",
      "accuracy =  0.7666666666666667\n",
      "precision =  0.7777777777777778\n",
      "recall =  0.7666666666666667\n",
      "f1 score =  0.7687400318979266\n"
     ]
    }
   ],
   "source": [
    "#sklearn\n",
    "print(\"Pengujian menggunakan sklearn:\")\n",
    "conf_sklearn = confusion_matrix(iris_y,pred)\n",
    "print(\"confusion_matrix\")\n",
    "print(conf_sklearn)\n",
    "print(\"accuracy = \",accuracy_score(iris_y,pred))\n",
    "weight = weight_f1score(iris_y)\n",
    "print(\"precision = \", precision_score(iris_y,pred,average=\"weighted\",zero_division=0))\n",
    "print(\"recall = \", weighted_recall(conf,weight,0))\n",
    "print(\"f1 score = \",weighted_f1(conf,weight,0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Lakukan pembelajaran FFNN untuk dataset iris dengan skema split train 90% dan test 10%, dan menampilkan kinerja serta confusion matrixnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kinerja(true,output):\n",
    "    pred = np.concatenate(output, axis=0) \n",
    "    pred = np.round(pred)\n",
    "    pred = pred.astype(int)\n",
    "    conf_sklearn = confusion_matrix(true,pred)\n",
    "    print(\"confusion_matrix\")\n",
    "    print(conf_sklearn)\n",
    "    print(\"accuracy = \",accuracy_score(true,pred))\n",
    "    weight = weight_f1score(true)\n",
    "    print(\"precision = \", precision_score(true,pred,average=\"weighted\",zero_division=0))\n",
    "    print(\"recall = \", weighted_recall(conf,weight,0))\n",
    "    print(\"f1 score = \",weighted_f1(conf,weight,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method Splitting\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from model import Model\n",
    "\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_feature_names = load_iris().feature_names\n",
    "iris_target_names = load_iris().target_names\n",
    "iris_X, iris_y = load_iris(return_X_y = True)\n",
    "\n",
    "def train_test(model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Membagi dataset train menjadi batch\n",
    "    mini_batch_X_train = []\n",
    "    mini_batch_y_train = []\n",
    "    batches_X_train = []\n",
    "    batches_y_train = []\n",
    "\n",
    "    for i in range (len(X_train)):\n",
    "        mini_batch_X_train.append(X_train[i])\n",
    "        mini_batch_y_train.append(y_train[i])\n",
    "        if (i % model.batch_size == model.batch_size - 1): # isi mini_batch sebanyak batch_size\n",
    "            batches_X_train.append(mini_batch_X_train)\n",
    "            batches_y_train.append(mini_batch_y_train)\n",
    "            mini_batch_X_train = []\n",
    "            mini_batch_y_train = []\n",
    "    \n",
    "    # Melakukan pembelajaran FFNN\n",
    "    outputs_train = model.fit(batches_X_train, batches_y_train, 0.1, 1, 20)\n",
    "    # print(model)\n",
    "    \n",
    "    # Melakukan FFNN pada test data\n",
    "    outputs_test = model.doffnn(X_test)\n",
    "    return outputs_train,outputs_test\n",
    "    # print(outputs[0])\n",
    "\n",
    "print(\"Method Splitting\")\n",
    "\n",
    "iris_X_train_stt, iris_X_test_stt, iris_y_train_stt, iris_y_test_stt = train_test_split(iris_X, iris_y, test_size = 0.1)\n",
    "\n",
    "# proses\n",
    "model = Model(\"model.txt\")\n",
    "pred_train, pred_test = train_test(model, iris_X_train_stt, iris_y_train_stt, iris_X_test_stt, iris_y_test_stt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinerja Dataset test\n",
      "confusion_matrix\n",
      "[[0 4 0]\n",
      " [0 5 0]\n",
      " [0 6 0]]\n",
      "accuracy =  0.3333333333333333\n",
      "precision =  0.1111111111111111\n",
      "recall =  0.7733333333333334\n",
      "f1 score =  0.7757575757575758\n"
     ]
    }
   ],
   "source": [
    "print(\"kinerja Dataset test\")\n",
    "kinerja(iris_y_test_stt,pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Lakukan pembelajaran FFNN untuk dataset iris (tersedia di Internet) dengan skema 10-fold cross validation, dan menampilkan kinerjanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 10-fold\n"
     ]
    }
   ],
   "source": [
    "print(\"Method 10-fold\")\n",
    "\n",
    "# cross val\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = Model(\"model.txt\")\n",
    "\n",
    "X = np.array(iris_X)\n",
    "y = np.array(iris_y)\n",
    "kf = KFold(n_splits=10)\n",
    "# kf.get_n_splits(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    iris_X_train_10f, iris_X_test_10f = X[train_index], X[test_index]\n",
    "    iris_y_train_10f, iris_y_test_10f = y[train_index], y[test_index]\n",
    "    # proses\n",
    "    train_test(model, iris_X_train_10f, iris_y_train_10f, iris_X_test_10f, iris_y_test_10f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinerja Dataset test\n",
      "confusion_matrix\n",
      "[[0 4 0]\n",
      " [0 5 0]\n",
      " [0 6 0]]\n",
      "accuracy =  0.3333333333333333\n",
      "precision =  0.1111111111111111\n",
      "recall =  0.7733333333333334\n",
      "f1 score =  0.7757575757575758\n"
     ]
    }
   ],
   "source": [
    "print(\"kinerja Dataset test\")\n",
    "kinerja(iris_y_test_stt,pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Simpan (save) model/hipotesis hasil pembelajaran skema full training ke file eksternal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saveModel(\"trained_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Baca (load) model/hipotesis dari file eksternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(\"trained_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Buat instance baru dengan memberi nilai untuk setiap atribut, lalu prediksi dengan memanfaatkan model/hipotesis dari hasil 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_instance = np.array([[4.3,3.2,2.1,1.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.doffnn(new_instance)[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edc21c5a34ac2fc55a67b6915f2492b5b6eacf8caff7b171695b2ce893d4b5a1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
